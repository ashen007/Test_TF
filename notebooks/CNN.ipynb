{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Convnets\n",
    "\n",
    "convolutional networks are stack Conv2D and MaxPooling2D layers."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.activations import relu, softmax\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import categorical_accuracy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create convolutional network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def create_network(shape):\n",
    "    # layers\n",
    "    input_layer = InputLayer(input_shape=shape)\n",
    "    # conv layers\n",
    "    conv_1 = Conv2D(32, kernel_size=(3, 3), activation=relu)\n",
    "    max_pool_1 = MaxPooling2D(pool_size=(2, 2))\n",
    "    conv_2 = Conv2D(64, kernel_size=(3, 3), activation=relu)\n",
    "    max_pool_2 = MaxPooling2D(pool_size=(2, 2))\n",
    "    conv_3 = Conv2D(64, kernel_size=(3, 3), activation=relu)\n",
    "    flat_layer = Flatten()\n",
    "    # dense layers\n",
    "    dense_1 = Dense(units=64, activation=relu)\n",
    "    output_layer = Dense(units=10, activation=softmax)\n",
    "\n",
    "    model = Sequential([input_layer,conv_1,max_pool_1,\n",
    "                        conv_2,max_pool_2,conv_3,\n",
    "                        flat_layer,dense_1,output_layer])\n",
    "    model.compile(optimizer=RMSprop(learning_rate=0.01),\n",
    "                  loss=CategoricalCrossentropy(),\n",
    "                  metrics=[categorical_accuracy, 'accuracy'])\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### network summery"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create_network(shape=(28,28,1)).summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A local file was found, but it seems to be incomplete or outdated because the auto file hash does not match the original value of 731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1 so we will re-download the data.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 124s 11us/step\n",
      "11501568/11490434 [==============================] - 124s 11us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data,train_label),(test_data,test_label) = mnist.load_data('../data')\n",
    "train_data.shape,train_label.shape,test_data.shape,test_label.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_data = train_data.reshape((60000,28,28,1))\n",
    "train_data = train_data.astype('float32')/255.0\n",
    "train_label = to_categorical(train_label)\n",
    "\n",
    "test_data = test_data.reshape((10000,28,28,1))\n",
    "test_data = test_data.astype('float32')\n",
    "test_label = to_categorical(test_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1875/1875 [==============================] - 17s 8ms/step - loss: 0.2331 - categorical_accuracy: 0.9413 - accuracy: 0.9413\n",
      "Epoch 2/15\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1555 - categorical_accuracy: 0.9650 - accuracy: 0.9650\n",
      "Epoch 3/15\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1824 - categorical_accuracy: 0.9631 - accuracy: 0.9631\n",
      "Epoch 4/15\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.1882 - categorical_accuracy: 0.9626 - accuracy: 0.9626\n",
      "Epoch 5/15\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2111 - categorical_accuracy: 0.9579 - accuracy: 0.9579\n",
      "Epoch 6/15\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.2307 - categorical_accuracy: 0.9529 - accuracy: 0.9529\n",
      "Epoch 7/15\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2389 - categorical_accuracy: 0.9468 - accuracy: 0.9468\n",
      "Epoch 8/15\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2508 - categorical_accuracy: 0.9441 - accuracy: 0.9441\n",
      "Epoch 9/15\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2414 - categorical_accuracy: 0.9460 - accuracy: 0.9460\n",
      "Epoch 10/15\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2425 - categorical_accuracy: 0.9433 - accuracy: 0.9433\n",
      "Epoch 11/15\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.2590 - categorical_accuracy: 0.9419 - accuracy: 0.9419\n",
      "Epoch 12/15\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.2659 - categorical_accuracy: 0.9398 - accuracy: 0.9398\n",
      "Epoch 13/15\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.2679 - categorical_accuracy: 0.9388 - accuracy: 0.9388\n",
      "Epoch 14/15\n",
      "1875/1875 [==============================] - 19s 10ms/step - loss: 0.3013 - categorical_accuracy: 0.9271 - accuracy: 0.9271\n",
      "Epoch 15/15\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.3038 - categorical_accuracy: 0.9313 - accuracy: 0.9313\n"
     ]
    }
   ],
   "source": [
    "network = create_network(shape=(28,28,1))\n",
    "history = network.fit(train_data,train_label,\n",
    "                      batch_size=32,\n",
    "                      epochs=15)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}